## 255*255*3 크기의 컬러 이미지를 읽고 처리하는 과정
- 아래의 5단계를 순차적으로 따른다.

```python
import torch
import numpy as np

# 0. 원본 이미지 데이터 생성 (예시)
# 실제로는 cv2.imread()나 PIL.Image.open() 등으로 이미지를 불러옵니다.
# 여기서는 0-255 사이의 값을 갖는 (224, 224, 3) 크기의 uint8 numpy 배열로 가정합니다.
original_image = np.random.randint(0, 256, (224, 224, 3), dtype=np.uint8)
print(f"초기 데이터 형태: {original_image.shape}, 데이터 타입: {original_image.dtype}")
# >>> 초기 데이터 형태: (224, 224, 3), 데이터 타입: uint8

# 1. 컬러 이미지 입력 데이터를 PyTorch 텐서로 변환
# np.array -> torch.tensor
image_tensor = torch.from_numpy(original_image)
print(f"\n1. 텐서 변환 후 형태: {image_tensor.shape}, 데이터 타입: {image_tensor.dtype}")
# >>> 1. 텐서 변환 후 형태: torch.Size([224, 224, 3]), 데이터 타입: torch.uint8

# 2. float 형태로 변환
image_tensor = image_tensor.float()
print(f"2. float 변환 후 데이터 타입: {image_tensor.dtype}")
# >>> 2. float 변환 후 데이터 타입: torch.float32

# 3. 0과 1 사이의 값으로 Normalize
# 각 픽셀 값을 255로 나누어 정규화합니다.
image_tensor = image_tensor / 255.0
print(f"3. 정규화 후 최대/최소값: {image_tensor.max():.1f} / {image_tensor.min():.1f}")
# >>> 3. 정규화 후 최대/최소값: 1.0 / 0.0

# 4. HWC (Height, Width, Channel) -> CHW (Channel, Height, Width) 로 차원 변경
# PyTorch 모델은 채널(Channel)이 가장 앞서는 형태를 입력으로 받습니다.
# [224, 224, 3] -> [3, 224, 224]
image_tensor = image_tensor.permute(2, 0, 1)
print(f"4. 차원 변경 후 형태: {image_tensor.shape}")
# >>> 4. 차원 변경 후 형태: torch.Size([3, 224, 224])

# 5. 배치화 작업 (Batch Dimension 추가)
# 모델에 입력하기 위해 배치(Batch) 차원을 추가합니다.
# [3, 224, 224] -> [1, 3, 224, 224] (배치 크기: 1)
batch_tensor = image_tensor.unsqueeze(0)
print(f"5. 배치화 후 최종 형태: {batch_tensor.shape}")
# >>> 5. 배치화 후 최종 형태: torch.Size([1, 3, 224, 224])
```

pytorch 의 torchvisions.transforms 을 사용하면 위 과정을 좀 더 손쉽게 표현 가능하다.
```python
import torch
from torchvision import transforms
from PIL import Image
import numpy as np

# 0. 원본 이미지 데이터 (PIL Image 또는 numpy array)
# 예시로 numpy 배열을 PIL Image로 변환
original_image_pil = Image.fromarray(original_image)


# 1~5. 변환 과정을 한 번에 정의
transform = transforms.Compose([
    transforms.ToTensor(),  # 1. PIL/numpy -> Tensor, 2. float 타입 변환, 3. 0-1 정규화, 4. HWC->CHW 변환
])

# 변환 적용
transformed_tensor = transform(original_image_pil)

# 5. 배치화
batch_tensor = transformed_tensor.unsqueeze(0)


print(f"최종 결과 형태: {batch_tensor.shape}")
print(f"최종 결과 데이터 타입: {batch_tensor.dtype}")
print(f"최종 결과 최대/최소값: {batch_tensor.max():.1f} / {batch_tensor.min():.1f}")

# >>> 최종 결과 형태: torch.Size([1, 3, 224, 224])
# >>> 최종 결과 데이터 타입: torch.float32
# >>> 최종 결과 최대/최소값: 1.0 / 0.0
```
